{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a640987",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# code from https://colab.research.google.com/drive/1wEPiGXToKfuNFGEjjoJsqlssuSbV8EU8#scrollTo=tCEDXLxq628O\n",
    "# Sentiment Classification with BERTbased model\n",
    "import transformers, tokenizers\n",
    "# !conda install -c conda-forge pytorch-lightning\n",
    "# !git clone https://github.com/davidtvs/pytorch-lr-finder.git && cd pytorch-lr-finder && python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "428171af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, logging, os\n",
    "from torch import nn\n",
    "from typing import List\n",
    "import torch.nn.functional as F\n",
    "from transformers import DistilBertTokenizer, AutoTokenizer, AutoModelWithLMHead, DistilBertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from functools import lru_cache\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from argparse import Namespace\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f67143c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685b22d04ce64caca4ac0f674c0ec90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b1b3579d76413180b3cd9256a2333a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7ec35479a44936b8d7c8dd4e89c21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb43c4d260f74e52b4783ab78c0f51be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcochan/anaconda3/envs/NLP/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:806: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a909e0df36047f7be627488a152e4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')\n",
    "model = AutoModelWithLMHead.from_pretrained(\"distilroberta-base\")\n",
    "base_model = model.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48270ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Elvis is the king of rock!\"\n",
    "enc = tokenizer.encode_plus(text)\n",
    "enc.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bee15397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9682, 9578, 16, 5, 8453, 9, 3152, 328, 2]\n",
      "tensor([[   0, 9682, 9578,   16,    5, 8453,    9, 3152,  328,    2]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0384,  0.0482, -0.0128,  ...,  0.0148, -0.0885,  0.0388],\n",
      "         [ 0.0312,  0.2362, -0.0594,  ..., -0.0862, -0.0779,  0.0986],\n",
      "         [-0.0213,  0.2983, -0.0144,  ...,  0.1338, -0.0386,  0.1351],\n",
      "         ...,\n",
      "         [-0.1052,  0.0377, -0.0083,  ...,  0.1869, -0.0304,  0.0325],\n",
      "         [-0.0163, -0.0976,  0.0186,  ..., -0.2109, -0.1637,  0.1759],\n",
      "         [-0.0542,  0.0595, -0.0695,  ..., -0.0484, -0.1007,  0.0362]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), pooler_output=None, hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n",
      "torch.Size([1, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "input = enc[\"input_ids\"]\n",
    "print(input)\n",
    "input = torch.tensor(input).unsqueeze(0)\n",
    "print(input)\n",
    "mask = torch.tensor(enc['attention_mask']).unsqueeze(0)\n",
    "print(mask)\n",
    "out = base_model(input, mask)\n",
    "print(out)\n",
    "print(out[0].shape)\n",
    "\n",
    "# out = base_model(torch.tensor(enc[\"input_ids\"]).unsqueeze(0), torch.tensor(enc[\"attention_mask\"]).unsqueeze(0))\n",
    "# print(out)\n",
    "# print(out[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af3958ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0337,  0.0782, -0.0158,  ...,  0.0062, -0.0636,  0.0063],\n",
      "        [ 0.0288,  0.2495, -0.0943,  ..., -0.1287, -0.0692,  0.1227],\n",
      "        [-0.0370,  0.3241, -0.0406,  ...,  0.1083, -0.0169,  0.1451],\n",
      "        ...,\n",
      "        [-0.0277, -0.0062,  0.1047,  ...,  0.1294,  0.0563,  0.0373],\n",
      "        [-0.1182,  0.0516, -0.0148,  ...,  0.1692, -0.0189,  0.0419],\n",
      "        [-0.0517,  0.1022, -0.0675,  ..., -0.0594, -0.0697, -0.0191]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "<s>Elvis is the king of rock</s>\n",
      "Length: 9\n",
      "torch.Size([9, 768])\n"
     ]
    }
   ],
   "source": [
    "t = \"Elvis is the king of rock\"\n",
    "enc = tokenizer.encode_plus(t)\n",
    "token_representations = base_model(torch.tensor(enc['input_ids']).unsqueeze(0))[0][0]\n",
    "print(token_reprensentations)\n",
    "print(tokenizer.decode(enc['input_ids']))\n",
    "print(f\"Length: {len(enc['input_ids'])}\")\n",
    "# print(\"Length: {}\".format(len(enc['input_ids'])))\n",
    "print(token_representations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ebeaa7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mish(input):\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "  \n",
    "class Mish(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return mish(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5678290",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmoModel(nn.Module):\n",
    "    def __init__(self, base_model, n_classes, base_model_output_size=768, dropout=0.05):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_model_output_size, base_model_output_size),\n",
    "            Mish(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_model_output_size, n_classes)\n",
    "        )\n",
    "        \n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.weight.data.normal_(mean=0.0, std=0.02)\n",
    "                if layer.bias is not None:\n",
    "                    layer.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input_, *args):\n",
    "        X, attention_mask = input_\n",
    "        hidden_states = self.base_model(X, attention_mask=attention_mask)\n",
    "        \n",
    "        # here I use only representation of <s> token, but you can easily use more tokens,\n",
    "        # maybe do some pooling / RNNs... go crazy here!\n",
    "\n",
    "        # use the [CLS] representation\n",
    " \n",
    "        return self.classifier(hidden_states[0][:, 0, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4419fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0147, -0.0957, -0.0712]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "classifier = EmoModel(AutoModelWithLMHead.from_pretrained(\"distilroberta-base\").base_model, 3)\n",
    "X = torch.tensor(enc[\"input_ids\"]).unsqueeze(0).to('cpu')\n",
    "attn = torch.tensor(enc[\"attention_mask\"]).unsqueeze(0).to('cpu')\n",
    "print(classifier((X, attn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a668dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
